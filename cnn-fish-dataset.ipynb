{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-13T16:42:17.141105Z","iopub.execute_input":"2021-06-13T16:42:17.141601Z","iopub.status.idle":"2021-06-13T16:42:18.14068Z","shell.execute_reply.started":"2021-06-13T16:42:17.141518Z","shell.execute_reply":"2021-06-13T16:42:18.137031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U efficientnet --quiet","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:43:03.421714Z","iopub.execute_input":"2021-06-13T16:43:03.421996Z","iopub.status.idle":"2021-06-13T16:43:12.505718Z","shell.execute_reply.started":"2021-06-13T16:43:03.421968Z","shell.execute_reply":"2021-06-13T16:43:12.504608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport cv2\n\nfrom PIL import Image\nimport tensorflow as tf\nimport tensorflow.keras as keras\n\nfrom tensorflow.keras.utils import to_categorical\nfrom efficientnet.tfkeras import preprocess_input\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom efficientnet.tfkeras import EfficientNetB3\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import datasets, layers, models\nfrom keras.layers import Dropout, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, Dense, Activation\nfrom keras.optimizers import RMSprop, Adam","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:43:15.487431Z","iopub.execute_input":"2021-06-13T16:43:15.487811Z","iopub.status.idle":"2021-06-13T16:43:16.331373Z","shell.execute_reply.started":"2021-06-13T16:43:15.487774Z","shell.execute_reply":"2021-06-13T16:43:16.330072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/train\n!mkdir /kaggle/working/val","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:43:36.933164Z","iopub.execute_input":"2021-06-13T16:43:36.933442Z","iopub.status.idle":"2021-06-13T16:43:37.485961Z","shell.execute_reply.started":"2021-06-13T16:43:36.933419Z","shell.execute_reply":"2021-06-13T16:43:37.484875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize_image(image, size=416):\n    ''' Resizing the image to a square (416x416) '''\n    w, h = image.size\n    longest_side = max(w, h)\n    # Scaling the image\n    image = image.resize((int(w*size/longest_side), int(h*size/longest_side)), Image.BICUBIC) \n    scaled_w, scaled_h = image.size\n\n    new_image = Image.new('RGB', (size, size))\n    new_image.paste(image, ((size - scaled_w) // 2, (size - scaled_h) // 2))\n    return new_image","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:43:41.452798Z","iopub.execute_input":"2021-06-13T16:43:41.453087Z","iopub.status.idle":"2021-06-13T16:43:41.459337Z","shell.execute_reply.started":"2021-06-13T16:43:41.453062Z","shell.execute_reply":"2021-06-13T16:43:41.458118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/futurefish/species.csv')\n\ntrain_data = []\nval_data = []\nclass_names = [row[1] for row in df.itertuples()]\n\nsets = ['train', 'val']\npath = ['/kaggle/input/futurefish/training.csv' ,\n        '/kaggle/input/futurefish/annotation.csv']\n\nimages_folder = '/kaggle/input/futurefish/data/data/'\n\nfor i in range(2):\n    csv_path =  path[i]\n    df = pd.read_csv(csv_path)\n    for row in df.itertuples():\n        file_id = row[1]\n        species_id = row[2]\n        new_filename = f'{file_id}.jpg'\n        new_filepath = '/kaggle/working/{}/{}'.format(sets[i], new_filename)\n        img = Image.open(f'{images_folder}{file_id}.jpg')\n        img = img.convert('RGB')\n        img = resize_image(img)\n        img.save(new_filepath, format='JPEG', quality=90)\n        \n        set_data = train_data if i == 0 else val_data\n        set_data.append((new_filepath,species_id))\n        \n        #if (row[0] % 100 == 0):\n            #print(row[0])\n       \n    \n\nlen(train_data), len(val_data), len(class_names)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:43:44.094661Z","iopub.execute_input":"2021-06-13T16:43:44.095007Z","iopub.status.idle":"2021-06-13T16:44:15.661628Z","shell.execute_reply.started":"2021-06-13T16:43:44.094979Z","shell.execute_reply":"2021-06-13T16:44:15.659684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:44:49.180282Z","iopub.execute_input":"2021-06-13T16:44:49.180657Z","iopub.status.idle":"2021-06-13T16:44:49.189595Z","shell.execute_reply.started":"2021-06-13T16:44:49.180627Z","shell.execute_reply":"2021-06-13T16:44:49.188604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_set(set_data):\n    X,y = [],[]\n    for filepath, species_id in set_data:\n        img = Image.open(filepath)\n        img = np.array(img)\n        X.append(img)\n        y.append(species_id)\n    X = np.array(X)\n    y = to_categorical(y)\n    return X, y\n\nX_train, y_train = load_set(train_data)\nX_val, y_val = load_set(val_data)\n\n\nX_train = preprocess_input(X_train)\nX_val = preprocess_input(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:44:53.452549Z","iopub.execute_input":"2021-06-13T16:44:53.452879Z","iopub.status.idle":"2021-06-13T16:45:01.66508Z","shell.execute_reply.started":"2021-06-13T16:44:53.452851Z","shell.execute_reply":"2021-06-13T16:45:01.664072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)\nfilepath1 = \"model_cnn.h5\"\nckpt1 = ModelCheckpoint(filepath1, monitor='loss', verbose=1, save_best_only=True, mode='min')\n\nmodel = models.Sequential()\nmodel.add(ZeroPadding2D((1, 1), input_shape=(300, 300, 3)))\nmodel.add(Convolution2D(4, 3, 3, activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(4, 3, 3, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(8, 3, 3, activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(8, 3, 3, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.6))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.6))\nmodel.add(Dense(20, activation='softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:45:30.422976Z","iopub.execute_input":"2021-06-13T16:45:30.423288Z","iopub.status.idle":"2021-06-13T16:45:30.621146Z","shell.execute_reply.started":"2021-06-13T16:45:30.42326Z","shell.execute_reply":"2021-06-13T16:45:30.620053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n        \nhistory = model.fit(X_train, y_train, callbacks=[es,ckpt1], batch_size=16, epochs=200, validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:45:33.604001Z","iopub.execute_input":"2021-06-13T16:45:33.604332Z","iopub.status.idle":"2021-06-13T16:58:18.852872Z","shell.execute_reply.started":"2021-06-13T16:45:33.604304Z","shell.execute_reply":"2021-06-13T16:58:18.85164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('model_cnn.h5')\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Model evaluation\ntest_loss, test_acc = model.evaluate(X_val, y_val, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T17:01:14.129813Z","iopub.execute_input":"2021-06-13T17:01:14.130139Z","iopub.status.idle":"2021-06-13T17:01:15.946296Z","shell.execute_reply.started":"2021-06-13T17:01:14.130111Z","shell.execute_reply":"2021-06-13T17:01:15.944957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 40\nplt.imshow((X_val[i]+1.)/2.)\nmodel.predict(np.array([X_val[i]]))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T17:01:24.201722Z","iopub.execute_input":"2021-06-13T17:01:24.202008Z","iopub.status.idle":"2021-06-13T17:01:24.882585Z","shell.execute_reply.started":"2021-06-13T17:01:24.201981Z","shell.execute_reply":"2021-06-13T17:01:24.881575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_video(path):\n    cap = cv2.VideoCapture(path)\n    success,image = cap.read()\n    if not success:\n        print('Could not open file or read frame')\n    else:\n        images = []\n        i = 0\n        while success:\n            img = Image.fromarray(image)\n            img = resize_image(img)\n            images.append(np.array(img))\n            \n            cap.set(cv2.CAP_PROP_POS_MSEC,i*500)\n            success,image = cap.read()\n            i += 1\n            if i > 15:\n                break\n        \n        images = np.array(images)\n        images = preprocess_input(images)\n        predictions = model.predict(images)\n        argmaxes = np.argmax(predictions, axis=-1)\n        predictions = predictions*100\n        print(argmaxes.shape)\n        \n        for i, img in enumerate(images):\n            plt.figure(figsize=(7,7))\n            plt.imshow(img/5.5+.5)\n            plt.axis('off')\n            plt.text(50, 50, 'Class:{} {:.2f}%'.format(class_names[argmaxes[i]], predictions[i][argmaxes[i]]), fontsize=15,color='White')\n    \n\ntest_video('../input/test-video-fish/test2.mp4')","metadata":{"execution":{"iopub.status.busy":"2021-06-13T17:01:27.223758Z","iopub.execute_input":"2021-06-13T17:01:27.224064Z","iopub.status.idle":"2021-06-13T17:01:37.90887Z","shell.execute_reply.started":"2021-06-13T17:01:27.22404Z","shell.execute_reply":"2021-06-13T17:01:37.907734Z"},"trusted":true},"execution_count":null,"outputs":[]}]}